<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="Sunburst7">
    
    <title>
        
            实验：神经网络预测Fashion—MNIST数据集 |
        
        Sunburst7&#39;s Blog
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/blog.svg">
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/css/font-awesome.min.css">
    <script id="hexo-configurations">
    let KEEP = window.KEEP || {};
    KEEP.hexo_config = {"hostname":"example.com","root":"/","language":"en","path":"search.json"};
    KEEP.theme_config = {"toc":{"enable":true,"number":true,"expand_all":false,"init_open":true},"style":{"primary_color":"#0066CC","avatar":"/images/希露菲.jpg","favicon":"/images/blog.svg","article_img_align":"left","left_side_width":"260px","content_max_width":"920px","hover":{"shadow":false,"scale":false},"first_screen":{"enable":true,"background_img":"/images/bg.svg","description":"遍履城山不求仙，独羇花月欲穷年，一罢掷杯秋泓饮，胜却青锋十三弦。"},"scroll":{"progress_bar":{"enable":false},"percent":{"enable":false}}},"local_search":{"enable":true,"preload":true},"code_copy":{"enable":true,"style":"default"},"pjax":{"enable":false},"lazyload":{"enable":true},"version":"3.4.5"};
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"};
  </script>
<meta name="generator" content="Hexo 5.4.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>


<body>
<div class="progress-bar-container">
    

    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            <header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
                <a class="logo-image" href="/">
                    <img src="/images/lady.jpg">
                </a>
            
            <a class="logo-title" href="/">
                Sunburst7&#39;s Blog
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                首页
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                时间线
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/categories"
                            >
                                分类
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/tag"
                            >
                                标签
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/about"
                            >
                                关于
                            </a>
                        </li>
                    
                    
                        <li class="menu-item search search-popup-trigger">
                            <i class="fas fa-search"></i>
                        </li>
                    
                </ul>
            </div>
            <div class="mobile">
                
                    <div class="icon-item search search-popup-trigger"><i class="fas fa-search"></i></div>
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">首页</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">时间线</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/categories">分类</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/tag">标签</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/about">关于</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="article-content-container">

        <div class="article-title">
            <span class="title-hover-animation">实验：神经网络预测Fashion—MNIST数据集</span>
        </div>

        
            <div class="article-header">
                <div class="avatar">
                    <img src="/images/%E5%B8%8C%E9%9C%B2%E8%8F%B2.jpg">
                </div>
                <div class="info">
                    <div class="author">
                        <span class="name">Sunburst7</span>
                        
                            <span class="author-label">Lv2</span>
                        
                    </div>
                    <div class="meta-info">
                        <div class="article-meta-info">
    <span class="article-date article-meta-item">
        <i class="fas fa-edit"></i>&nbsp;
        <span class="pc">2022-01-10 23:37:51</span>
        <span class="mobile">2022-01-10 23:37</span>
    </span>
    
        <span class="article-categories article-meta-item">
            <i class="fas fa-folder"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    
    
        <span class="article-tags article-meta-item">
            <i class="fas fa-tags"></i>&nbsp;
            <ul>
                
                    <li>
                        <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a>&nbsp;
                    </li>
                
                    <li>
                        | <a href="/tags/python/">python</a>&nbsp;
                    </li>
                
            </ul>
        </span>
    

    
    
        <span class="article-wordcount article-meta-item">
            <i class="fas fa-file-word"></i>&nbsp;<span>4.4k Words</span>
        </span>
    
    
        <span class="article-min2read article-meta-item">
            <i class="fas fa-clock"></i>&nbsp;<span>18 Mins</span>
        </span>
    
    
        <span class="article-pv article-meta-item">
            <i class="fas fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv"></span>
        </span>
    
</div>

                    </div>
                </div>
            </div>
        

        <div class="article-content markdown-body">
            <h1 id="实验数据"><a href="#实验数据" class="headerlink" title="实验数据"></a>实验数据</h1><p>Fashion-MNIST数据集，数据集中包含 60000 张训练样本，10000 张测试 样本，可将训练样本划分为49000 张样本的训练集和1000 张样本的验证集，测 试集可只取1000 张测试样本。其中每个样本都是 28×28 像素的灰度照片，每 个像素点包括RGB三个数值，数值范围0 ~ 255，所有照片分属10个不同的类别。</p>
<img src="/2022/01/10/%E5%AE%9E%E9%AA%8C%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%A2%84%E6%B5%8BFashion%E2%80%94MNIST%E6%95%B0%E6%8D%AE%E9%9B%86/image-20211128153909041.png" class="" title="image-20211128153909041">

<p>灰度与像素值的关系：</p>
<ul>
<li><p>图像的灰度化： 灰度就是没有色彩，RGB色彩分量全部相等。图像的灰度化就是让像素点矩阵中的每一个像素点都满足关系：R=G=B，此时的这个值叫做灰度值。如RGB(100,100,100)就代表灰度值为100,RGB(50,50,50)代表灰度值为50。</p>
</li>
<li><p>灰度值与像素值的关系： 如果对于一张本身就是灰度图像（8位灰度图像）来说，他的像素值就是它的灰度值，如果是一张彩色图像，则它的灰度值需要经过函数映射来得到。灰度图像是由纯黑和纯白来过渡得到的，在黑色中加入白色就得到灰色，纯黑和纯白按不同的比例来混合就得到不同的灰度值。R=G=B=255为白色，R=G=B=0为黑色，R=G=B=小于255的某个整数时，此时就为某个灰度值。</p>
</li>
</ul>
<h1 id="实验要求"><a href="#实验要求" class="headerlink" title="实验要求"></a>实验要求</h1><ol>
<li><p>用神经网络对给定的数据集进行分类，画出loss图，给出在测试集上的精确度；</p>
</li>
<li><p>不能使用 pytorch 等框架，也不能使用库函数，所有算法都要自己实现</p>
</li>
<li><p>神经网络结构图如下图所示：</p>
 <img src="/2022/01/10/%E5%AE%9E%E9%AA%8C%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%A2%84%E6%B5%8BFashion%E2%80%94MNIST%E6%95%B0%E6%8D%AE%E9%9B%86/image-20211128153820318.png" class="" title="image-20211128153820318"></li>
<li><p>整个神经网络包括 3 层——输入层，隐藏层，输出层。输入层有28x28x3个神经元，隐藏层有 50个神经元，输出层有 10 个神经元（对应 10 个类别）。</p>
</li>
<li><p>附加：可以试着修改隐藏层神经元数，层数，学习率，正则化权重等参数探究参数对实验结果的影响</p>
</li>
</ol>
<h1 id="实验思路与代码"><a href="#实验思路与代码" class="headerlink" title="实验思路与代码"></a>实验思路与代码</h1><p>实验要求设计一个三层的全连接神经网络，实现分类的功能。<strong>实验原理</strong>请见我的博客：<a class="link" target="_blank" rel="noopener" href="https://blog.csdn.net/qq_45785407/article/details/121539815">神经网络基础与反向传播_Sunburst7的博客-CSDN博客<i class="fas fa-external-link-alt"></i></a></p>
<p>神经网络的每次迭代主要包括以下几个步骤：</p>
<ul>
<li>传入训练图片灰度矩阵/数组</li>
<li>进行前馈运算，计算出输出层10个神经元预测的标签</li>
<li>与期望的标签计算Loss，更新隐含层（Hidden）到输出层（Output）的权值</li>
<li>计算<strong>隐含层的敏感度</strong>，更新输入层（Input）到隐含层的权值</li>
<li>传入测试图片灰度矩阵，进行预测。</li>
<li>统计</li>
</ul>
<p>起初我的设计充满了面向对象的思想，导致在进行大数据集的运算时消耗时间很长，无法训练神经网络，受到参考【2】【3】【4】中博客的启发，改变思路，采用矩阵运算的思想成功训练出一个良好的神经网络。</p>
<h2 id="初始的设想"><a href="#初始的设想" class="headerlink" title="初始的设想"></a>初始的设想</h2><p>我准备编写一个神经元类表示单个神经元，该神经元有以下属性，手绘原理图：</p>
<img src="/2022/01/10/%E5%AE%9E%E9%AA%8C%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%A2%84%E6%B5%8BFashion%E2%80%94MNIST%E6%95%B0%E6%8D%AE%E9%9B%86/image-20211128160151169.png" class="" title="image-20211128160151169">

<ul>
<li><p>权值数组Weights：上一层与该神经元相连的所有神经元的权值</p>
</li>
<li><p>偏置Bias</p>
</li>
<li><p>输入值数组Inputs与输出值Output</p>
</li>
<li><p>激活函数</p>
</li>
<li><p>敏感度：定义可见实验原理博客</p>
</li>
<li><p>神经元类型Type：标识是输入层还是输出层还是隐含层神经元</p>
</li>
</ul>
<p>每个神经元有两个函数，分别代表前馈与反向传播。</p>
<ul>
<li>前馈：将输入值与权值进行向量的内积，加上偏置，在传入激活函数，输出最后的值</li>
<li>反向传播：对于输入层与输出层不同，利用传入的敏感度数组与权值数组更新自身的权值矩阵。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">if</span> x&gt;=<span class="number">0</span>:      <span class="comment">#对sigmoid函数的优化，避免了出现极大的数据溢出</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1.0</span>/(<span class="number">1</span>+np.exp(-x))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> np.exp(x)/(<span class="number">1</span>+np.exp(x))</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Neuron</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, weights, bias, ntype</span>):</span></span><br><span class="line">        <span class="comment"># 上一层与之相连的weights array</span></span><br><span class="line">        self.weights = weights</span><br><span class="line">        <span class="comment"># 偏置 bias</span></span><br><span class="line">        self.bias = bias</span><br><span class="line">        <span class="comment"># input array</span></span><br><span class="line">        self.inputs = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 总的输出 z_k</span></span><br><span class="line">        self.output = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 一个神经元的敏感度</span></span><br><span class="line">        self.sensitivity = <span class="number">0.0</span></span><br><span class="line">        <span class="comment"># 神经元的类型:Input Hidden Output</span></span><br><span class="line">        self.ntype = ntype</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__str__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">"weights: \n"</span>+<span class="built_in">str</span>(self.weights)+<span class="string">"\nbias:\n"</span>+<span class="built_in">str</span>(self.bias)+<span class="string">"\ninputs:\n"</span>+<span class="built_in">str</span>(self.inputs)+<span class="string">"\noutput:\n"</span>+<span class="built_in">str</span>(self.output)+<span class="string">"\nsensitivity\n"</span>+<span class="built_in">str</span>(self.sensitivity)+<span class="string">"\ntype:\n"</span>+<span class="built_in">str</span>(self.ntype)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">feedForward</span>(<span class="params">self, inputs:np.array</span>):</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        前馈</span></span><br><span class="line"><span class="string">        :param inputs: 输入的向量</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.inputs = inputs</span><br><span class="line">        <span class="comment"># weight inputs, add bias, then use the activation function</span></span><br><span class="line">        total = np.dot(self.weights, self.inputs) + self.bias</span><br><span class="line">        <span class="comment"># 计算神经元的输出</span></span><br><span class="line">        <span class="comment"># 如果是输入层，不需要带入激活函数f</span></span><br><span class="line">        <span class="keyword">if</span> self.ntype == <span class="string">'Input'</span>:</span><br><span class="line">            self.output = total</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.output = sigmoid(total)</span><br><span class="line">        <span class="keyword">return</span> self.output</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">backPropagation</span>(<span class="params">self ,eta ,tk ,sensitivities ,weights</span>):</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        反向传递更新权值</span></span><br><span class="line"><span class="string">        :param eta: 学习率</span></span><br><span class="line"><span class="string">        :param tk: 真实标签</span></span><br><span class="line"><span class="string">        :param sensitivities: 该神经元如果不是输出层，隐含层下一层所有神经元的敏感度</span></span><br><span class="line"><span class="string">        :param weights: 该神经元如果不是输出层，与该神经元相连的下一层的所有权值</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="keyword">if</span> self.ntype == <span class="string">'Output'</span>:</span><br><span class="line">            <span class="comment"># 计算f'(net)=f(net)*(1-f(net))</span></span><br><span class="line">            derivative_f = self.output*(<span class="number">1</span>-self.output)</span><br><span class="line">            <span class="comment"># 计算loss'(zk)=-(tk-zk)</span></span><br><span class="line">            derivative_loss = -(tk - self.output)</span><br><span class="line">            <span class="comment"># 计算该神经元的敏感度 sensitivity = -f'(net)*loss'(zk)</span></span><br><span class="line">            self.sensitivity = -derivative_f*derivative_loss</span><br><span class="line">            <span class="comment"># 更新权重</span></span><br><span class="line">            self.weights = self.weights + eta*self.sensitivity*np.array(self.inputs)</span><br><span class="line">        <span class="keyword">elif</span> self.ntype == <span class="string">'Hidden'</span>:</span><br><span class="line">            <span class="comment"># 计算f'(net)=f(net)*(1-f(net))</span></span><br><span class="line">            derivative_f = self.output * (<span class="number">1</span> - self.output)</span><br><span class="line">            <span class="comment"># 计算隐含层单元的敏感度 sensitivity = f'(net)*&lt;下一层所有神经元的敏感度，该神经元与下一层相连的权重&gt;</span></span><br><span class="line">            self.sensitivity = derivative_f*np.dot(sensitivities,weights)</span><br><span class="line">            <span class="comment"># 更新权重</span></span><br><span class="line">            self.weights = self.weights + eta*self.sensitivity*np.array(self.inputs)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span></span><br></pre></td></tr></table></figure>

<p>再编写一个神经网络类构造三层神经元并进行feedForward与backPropagation的参数传递工作：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> gzip</span><br><span class="line"><span class="keyword">from</span> exp4.Neuron1 <span class="keyword">import</span> Neuron</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">if</span> x&gt;=<span class="number">0</span>:      <span class="comment">#对sigmoid函数的优化，避免了出现极大的数据溢出</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1.0</span>/(<span class="number">1</span>+np.exp(-x))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> np.exp(x)/(<span class="number">1</span>+np.exp(x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义加载数据的函数，加载4个zip格式文件</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_data</span>(<span class="params">data_folder</span>):</span></span><br><span class="line">  files = [</span><br><span class="line">      <span class="string">'train-labels-idx1-ubyte.gz'</span>, <span class="string">'train-images-idx3-ubyte.gz'</span>,</span><br><span class="line">      <span class="string">'t10k-labels-idx1-ubyte.gz'</span>, <span class="string">'t10k-images-idx3-ubyte.gz'</span></span><br><span class="line">  ]</span><br><span class="line">  paths = []</span><br><span class="line">  <span class="keyword">for</span> fname <span class="keyword">in</span> files:</span><br><span class="line">    paths.append(os.path.join(data_folder,fname))</span><br><span class="line">  <span class="keyword">with</span> gzip.<span class="built_in">open</span>(paths[<span class="number">0</span>], <span class="string">'rb'</span>) <span class="keyword">as</span> lbpath:</span><br><span class="line">    y_train = np.frombuffer(lbpath.read(), np.uint8, offset=<span class="number">8</span>)</span><br><span class="line">  <span class="keyword">with</span> gzip.<span class="built_in">open</span>(paths[<span class="number">1</span>], <span class="string">'rb'</span>) <span class="keyword">as</span> imgpath:</span><br><span class="line">    x_train = np.frombuffer(</span><br><span class="line">        imgpath.read(), np.uint8, offset=<span class="number">16</span>).reshape(<span class="built_in">len</span>(y_train), <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">  <span class="keyword">with</span> gzip.<span class="built_in">open</span>(paths[<span class="number">2</span>], <span class="string">'rb'</span>) <span class="keyword">as</span> lbpath:</span><br><span class="line">    y_test = np.frombuffer(lbpath.read(), np.uint8, offset=<span class="number">8</span>)</span><br><span class="line">  <span class="keyword">with</span> gzip.<span class="built_in">open</span>(paths[<span class="number">3</span>], <span class="string">'rb'</span>) <span class="keyword">as</span> imgpath:</span><br><span class="line">    x_test = np.frombuffer(</span><br><span class="line">        imgpath.read(), np.uint8, offset=<span class="number">16</span>).reshape(<span class="built_in">len</span>(y_test), <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">  <span class="keyword">return</span> (x_train, y_train), (x_test, y_test)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">makeTrueLabels</span>(<span class="params">trueLabel</span>):</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    生成传递给输出层的期望标签数组</span></span><br><span class="line"><span class="string">    :param trueLabel:</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    labels = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">        <span class="keyword">if</span> trueLabel == i:</span><br><span class="line">            labels.append(<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            labels.append(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> labels</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NeuronNetwork</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,train_images,train_labels,test_images,test_labels</span>):</span></span><br><span class="line">        self.inputLayer = []</span><br><span class="line">        self.hiddenLayer = []</span><br><span class="line">        self.outputLayer = []</span><br><span class="line">        self.train_images = train_images</span><br><span class="line">        self.train_labels = train_labels</span><br><span class="line">        self.test_images = test_images</span><br><span class="line">        self.test_labels = test_labels</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 从输入层到隐含层权值的初始化</span></span><br><span class="line">        initWeight_1 = np.random.uniform(-<span class="number">1</span>/np.sqrt(<span class="number">784</span>),<span class="number">1</span>/np.sqrt(<span class="number">784</span>),(<span class="number">50</span>,<span class="number">784</span>))</span><br><span class="line">        <span class="comment"># 从隐含层到输出层权值的初始化</span></span><br><span class="line">        initWeight_2 = np.random.uniform(-<span class="number">1</span>/np.sqrt(<span class="number">50</span>),<span class="number">1</span>/np.sqrt(<span class="number">50</span>),(<span class="number">10</span>,<span class="number">50</span>))</span><br><span class="line">        <span class="comment"># 偏置初始化</span></span><br><span class="line">        bias = np.random.normal(<span class="number">0</span>,<span class="number">0.5</span>,<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 初始化输入层</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">784</span>):</span><br><span class="line">            neuron = Neuron(<span class="number">1</span>,<span class="number">0</span>,ntype=<span class="string">'Input'</span>)</span><br><span class="line">            self.inputLayer.append(neuron)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 初始化隐藏层</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line">            neuron = Neuron(initWeight_1[i],bias[<span class="number">0</span>],ntype=<span class="string">'Hidden'</span>)</span><br><span class="line">            self.hiddenLayer.append(neuron)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 初始化输出层</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">            neuron = Neuron(initWeight_2[i],bias[<span class="number">1</span>],ntype=<span class="string">'Output'</span>)</span><br><span class="line">            self.outputLayer.append(neuron)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">iteration</span>(<span class="params">self</span>):</span></span><br><span class="line">        T = <span class="number">0</span></span><br><span class="line">        N = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 依次将60000章图片训练一边</span></span><br><span class="line">        <span class="keyword">for</span> m <span class="keyword">in</span> <span class="built_in">range</span>(self.train_images.shape[<span class="number">0</span>]):</span><br><span class="line">            <span class="comment"># 输入层(784个神经元)的输出</span></span><br><span class="line">            y_i = []</span><br><span class="line">            <span class="comment"># 对于每张图片的784个像素点</span></span><br><span class="line">            <span class="keyword">for</span> row <span class="keyword">in</span> <span class="built_in">range</span>(self.train_images.shape[<span class="number">1</span>]):</span><br><span class="line">                <span class="keyword">for</span> col <span class="keyword">in</span> <span class="built_in">range</span>(self.train_images.shape[<span class="number">2</span>]):</span><br><span class="line">                    y_i.append(</span><br><span class="line">                        self.inputLayer[<span class="number">28</span> * row + col].feedForward(inputs=np.array(train_images[m][row][col]))</span><br><span class="line">                    )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 隐藏层(50个神经元)的输出</span></span><br><span class="line">            y_h = []</span><br><span class="line">            <span class="keyword">for</span> hidden_neuron <span class="keyword">in</span> self.hiddenLayer:</span><br><span class="line">                y_h.append(hidden_neuron.feedForward(y_i))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 输出层的标签：预测标签</span></span><br><span class="line">            y_o = []</span><br><span class="line">            <span class="keyword">for</span> output_neuron <span class="keyword">in</span> self.outputLayer:</span><br><span class="line">                y_o.append(output_neuron.feedForward(y_h))</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 进行预测，统计预测正误</span></span><br><span class="line">            forecastLabel = y_o.index(np.array(y_o).<span class="built_in">max</span>())</span><br><span class="line">            <span class="keyword">if</span> forecastLabel == train_labels[m]:</span><br><span class="line">                T+=<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                N+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 期望值数组</span></span><br><span class="line">            trueLabels = makeTrueLabels(trueLabel=forecastLabel)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 对输出层进行反向传播</span></span><br><span class="line">            output_sensitivities = [] <span class="comment"># 输出层所有节点的敏感度</span></span><br><span class="line">            output_weights = [] <span class="comment"># 输出层所有节点的权重</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">                self.outputLayer[i].backPropagation(eta=<span class="number">0.1</span>,tk=trueLabels[i],sensitivities=<span class="literal">None</span>,weights=<span class="literal">None</span>)</span><br><span class="line">                <span class="comment"># 保存更新过的敏感度</span></span><br><span class="line">                output_sensitivities.append(self.outputLayer[i].sensitivity)</span><br><span class="line">                output_weights.append(self.outputLayer[i].weights)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 对隐含层进行反向传播</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">50</span>):</span><br><span class="line">                <span class="comment"># 隐含层每个神经元连接的10个输出层神经元的权值</span></span><br><span class="line">                linkedWeights = [arr[i] <span class="keyword">for</span> arr <span class="keyword">in</span> output_weights]</span><br><span class="line">                self.hiddenLayer[i].backPropagation(eta=<span class="number">0.1</span>,tk=<span class="literal">None</span>,sensitivities=output_sensitivities,weights=linkedWeights)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> T, N</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 传入数据集</span></span><br><span class="line">(train_images, train_labels), (test_images, test_labels) = load_data(<span class="string">''</span>)</span><br><span class="line">train_images = train_images[<span class="number">0</span>:<span class="number">500</span>:<span class="number">1</span>]</span><br><span class="line">train_labels = train_labels[<span class="number">0</span>:<span class="number">500</span>:<span class="number">1</span>]</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">    定义统计信息：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">n = <span class="number">100</span></span><br><span class="line">positive = []</span><br><span class="line">negative = []</span><br><span class="line">nn = NeuronNetwork(train_images=train_images,train_labels=train_labels,test_images=test_images,test_labels=test_labels)</span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    T,N = nn.iteration()</span><br><span class="line">    positive.append(T)</span><br><span class="line">    negative.append(N)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>该神经网络只能运行在少量的样本上，不能满足需要</p>
<img src="/2022/01/10/%E5%AE%9E%E9%AA%8C%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%A2%84%E6%B5%8BFashion%E2%80%94MNIST%E6%95%B0%E6%8D%AE%E9%9B%86/Snipaste_2021-11-26_23-59-22.png" class="" title="Snipaste_2021-11-26_23-59-22">

<h2 id="改进思路：矩阵运算"><a href="#改进思路：矩阵运算" class="headerlink" title="改进思路：矩阵运算"></a>改进思路：矩阵运算</h2><p>之前思路中更新的过程太慢，每次都要一张一张图片传入，同时大量的对象也拖慢了运算的速度，因此我取消了神经元类，而在神经网络中保存两个矩阵，分别代表从输入层到隐含层与从隐含层到输出层的权值。</p>
<img src="/2022/01/10/%E5%AE%9E%E9%AA%8C%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%A2%84%E6%B5%8BFashion%E2%80%94MNIST%E6%95%B0%E6%8D%AE%E9%9B%86/image-20211128161424625.png" class="" title="image-20211128161424625">

<p>神经网络类通过输入层节点数、隐含层节点数、输出层节点数、学习率进行初始化，同时初始化两个权值矩阵以及一个偏置数组。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 制作一个神经网络算法的类，其名为神经网络，相当于函数库，直接进行调用里面的函数即可。</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NeuralNetwork</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,inputNeurons,hiddenNeurons,outputNeurons,lr</span>):</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        神经网络构造方法</span></span><br><span class="line"><span class="string">        :param inputNeurons:输入层神经元个数</span></span><br><span class="line"><span class="string">        :param hiddenNeurons:隐含层神经元个数</span></span><br><span class="line"><span class="string">        :param outputNeurons:输出层神经元个数</span></span><br><span class="line"><span class="string">        :param lr:学习率</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        self.iNeuron_num = inputNeurons</span><br><span class="line">        self.hNeuron_num = hiddenNeurons</span><br><span class="line">        self.oNeuron_num = outputNeurons</span><br><span class="line">        self.learnRate = lr <span class="comment"># 学习率</span></span><br><span class="line">        self.f = <span class="keyword">lambda</span> x: ssp.expit(x) <span class="comment"># 设置激活函数f为Sigmod(x)激活函数</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 设置输入层与隐藏层直接的权重关系矩阵以及隐藏层与输出层之间的权重关系矩阵,初始值为正态分布</span></span><br><span class="line">        self.weights_i_h = np.random.normal(<span class="number">0.0</span>, <span class="number">1</span>/np.sqrt(hiddenNeurons), (self.hNeuron_num, self.iNeuron_num))</span><br><span class="line">        self.weights_h_o = np.random.normal(<span class="number">0.0</span>, <span class="number">1</span>/np.sqrt(hiddenNeurons), (self.oNeuron_num, self.hNeuron_num))</span><br><span class="line">        <span class="comment"># 偏置初始化</span></span><br><span class="line">        self.bias = np.random.normal(<span class="number">0</span>, <span class="number">0.5</span>, <span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<p><strong>对输入的图片</strong>与标签进行<strong>两步处理</strong>：</p>
<ul>
<li><p>归一化</p>
<ul>
<li>对于图片将所有的灰度(0-255)全部映射到(0.01-0.99)上</li>
<li>对于每一个表示分类结果的标签(0-9)重新构造一个长度为10的数组，下标对应每个标签，若真实分类标签为8，则数组[7] = 0.99，其他位置的值为0.01，近似表示该图片真实标签的概率。</li>
</ul>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对60000张图片进行遍历</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">60000</span>):</span><br><span class="line">    <span class="comment"># 测试集的28*28矩阵转化为784的一维数组</span></span><br><span class="line">    img = train_images[i].reshape(train_images.shape[<span class="number">1</span>]*train_images.shape[<span class="number">2</span>])</span><br><span class="line">    <span class="comment"># 进行归一化：除以255，再乘以0.99，最后加上0。01，保证所有的数据都在0.01到1.00之间</span></span><br><span class="line">    train_matrix[:,i] = (img/<span class="number">255.0</span>)*<span class="number">0.99</span>+<span class="number">0.01</span></span><br><span class="line">    <span class="comment"># 建立准确输出结果矩阵，对应的位置标签数值为0.99，其他位置为0.01</span></span><br><span class="line">    <span class="comment"># 第i张图片代表第i列，行数代表正确的标签</span></span><br><span class="line">    train_labels_matrix[train_labels[i],i] = <span class="number">0.99</span></span><br><span class="line">    </span><br><span class="line"><span class="comment"># 对10000章测试集图片进行处理</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000</span>):</span><br><span class="line">    <span class="comment"># 训练集的28*28矩阵转化为784的一维数组</span></span><br><span class="line">    test_img = test_images[i].reshape(test_images.shape[<span class="number">1</span>] * test_images.shape[<span class="number">2</span>])</span><br><span class="line">    <span class="comment"># 更新输入到神经网络中的训练集矩阵</span></span><br><span class="line">    test_matrix[:,i] = (test_img/<span class="number">255.0</span>)*<span class="number">0.99</span>+<span class="number">0.01</span></span><br><span class="line">    <span class="comment"># 建立准确输出结果矩阵，对应的位置标签数值为0.99，其他位置为0.01</span></span><br><span class="line">    test_label_matrix[test_labels[i],i] = <span class="number">0.99</span></span><br></pre></td></tr></table></figure></li>
<li><p>Reshape：将输入的图片灰度与标签从新组合</p>
  <img src="/2022/01/10/%E5%AE%9E%E9%AA%8C%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%A2%84%E6%B5%8BFashion%E2%80%94MNIST%E6%95%B0%E6%8D%AE%E9%9B%86/image-20211128162535151.png" class="" title="image-20211128162535151"></li>
</ul>
<p>整个前馈的矩阵运算的过程如图：</p>
<img src="/2022/01/10/%E5%AE%9E%E9%AA%8C%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%A2%84%E6%B5%8BFashion%E2%80%94MNIST%E6%95%B0%E6%8D%AE%E9%9B%86/image-20211128164044624.png" class="" title="image-20211128164044624">

<p>BP的过程主要分为两个部分：</p>
<ul>
<li><p>对于输出层到隐含层：</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">计算f'(net) = f(net)*(1-f(net))</span><br><span class="line">计算loss'(zk)=-(tk-zk)</span><br><span class="line">计算对于每张图片该神经元的敏感度(10,60000):</span><br><span class="line">sensitivity = -f'(output_f_net)*loss'(zk) = (tk-zk)*f(output_f_net)*(1-f(output_f_net))[矩阵对应位置相乘]</span><br><span class="line">更新权重:学习率*敏感度(10,60000) @ 50个隐含层层神经元的输出(60000,50)</span><br></pre></td></tr></table></figure></li>
<li><p>对于隐含层到输入层：</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">计算对于每张图片50个隐含层神经元的每一个神经元的从输出层传入的敏感度（50*60000)：</span><br><span class="line">输出层敏感度的加权和*f'(net)</span><br><span class="line">更新权重</span><br></pre></td></tr></table></figure></li>
</ul>
<p>完整的训练过程如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span>(<span class="params">self,featuresMatrix,targetMatrix,iterateNum</span>):</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    神经网络一次训练</span></span><br><span class="line"><span class="string">    :param featuresMatrix: 784*60000的图片灰度矩阵 也是隐含层的输入</span></span><br><span class="line"><span class="string">    :param targetMatrix: 10*60000的期望值矩阵 tk</span></span><br><span class="line"><span class="string">    :param iterateNum: 迭代序号</span></span><br><span class="line"><span class="string">    :return: 返回训练正确率</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    T = <span class="number">0</span></span><br><span class="line">    N = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 前馈 feedforward</span></span><br><span class="line">    <span class="comment"># 隐藏层net（50*60000）计算</span></span><br><span class="line">    hidden_net = (self.weights_i_h @ featuresMatrix)+self.bias[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 隐藏层输出f(hidden_net)</span></span><br><span class="line">    hidden_f_net = self.f(hidden_net)</span><br><span class="line">    <span class="comment"># 输出层net(10*60000) 计算</span></span><br><span class="line">    output_net = (self.weights_h_o @ hidden_f_net)+self.bias[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 输出层输出f(output_net) zk</span></span><br><span class="line">    output_f_net = self.f(output_net)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 统计网络预测正确率</span></span><br><span class="line">    <span class="keyword">for</span> imgIndex <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">60000</span>):</span><br><span class="line">        <span class="comment"># 返回输出层10个神经元最大值下标 与 预测标签</span></span><br><span class="line">        <span class="keyword">if</span> output_f_net[:,imgIndex].argmax() == targetMatrix[:,imgIndex].argmax():</span><br><span class="line">            T+=<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            N+=<span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"第"</span>+iterateNum+<span class="string">"次训练集迭代正确率："</span>+<span class="built_in">str</span>(T/<span class="number">60000</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 反向传播运算 backPropagation</span></span><br><span class="line">    <span class="comment"># 对于输出层到隐含层</span></span><br><span class="line">    output_errors = targetMatrix - output_f_net</span><br><span class="line">    <span class="comment"># 计算f'(net) = f(net)*(1-f(net))</span></span><br><span class="line">    <span class="comment"># 计算loss'(zk)=-(tk-zk)</span></span><br><span class="line">    <span class="comment"># 计算对于每张图片该神经元的敏感度(10,60000) sensitivity = -f'(net)*loss'(zk) = (tk-zk)*f(net)*(1-f(net))[矩阵对应位置相乘]</span></span><br><span class="line">    sensitivities = output_errors * output_f_net * (<span class="number">1.0</span> - output_f_net)</span><br><span class="line">    <span class="comment"># 更新权重 学习率* 敏感度(10,60000) @ 50个隐含层层神经元的输出(60000,50)</span></span><br><span class="line">    self.weights_h_o += self.learnRate * (sensitivities @ hidden_f_net.T)</span><br><span class="line">    <span class="comment"># 对于隐含层到输入层</span></span><br><span class="line">    <span class="comment"># 计算对于每张图片50个隐含层神经元的每一个敏感度（50*60000） = 输出层敏感度的加权和*f'(net)</span></span><br><span class="line">    hidden_sensitivities = (self.weights_h_o.T @ sensitivities) * hidden_f_net * (<span class="number">1</span> - hidden_f_net)</span><br><span class="line">    <span class="comment"># 更新权重</span></span><br><span class="line">    self.weights_i_h += self.learnRate * ( hidden_sensitivities @ featuresMatrix.T)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> T/<span class="number">60000</span></span><br></pre></td></tr></table></figure>

<p>预测的过程就是进行一遍前馈的过程：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">self,testMatrix,targetMatrix,iterateNum</span>):</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    利用神经网络对训练集进行一次测试</span></span><br><span class="line"><span class="string">    :param testMatrix: 784*10000的灰度矩阵</span></span><br><span class="line"><span class="string">    :param targetMatrix: 10*10000的预测标签矩阵</span></span><br><span class="line"><span class="string">    :param iterateNum: 迭代序号</span></span><br><span class="line"><span class="string">    :return: 返回训练正确率</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    T = <span class="number">0</span></span><br><span class="line">    N = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 前馈 feedforward</span></span><br><span class="line">    <span class="comment"># 隐藏层net（50*60000）计算</span></span><br><span class="line">    hidden_net = (self.weights_i_h @ testMatrix) + self.bias[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 隐藏层输出f(hidden_net)</span></span><br><span class="line">    hidden_f_net = self.f(hidden_net)</span><br><span class="line">    <span class="comment"># 输出层net(10*60000) 计算</span></span><br><span class="line">    output_net = (self.weights_h_o @ hidden_f_net) + self.bias[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 输出层输出f(output_net) zk</span></span><br><span class="line">    output_f_net = self.f(output_net)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 统计网络预测正确率</span></span><br><span class="line">    <span class="keyword">for</span> imgIndex <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000</span>):</span><br><span class="line">        <span class="comment"># 返回输出层10个神经元最大值下标 与 预测标签</span></span><br><span class="line">        <span class="keyword">if</span> output_f_net[:, imgIndex].argmax() == targetMatrix[:, imgIndex].argmax():</span><br><span class="line">            T += <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            N += <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"第"</span> + iterateNum + <span class="string">"次测试集迭代正确率："</span> + <span class="built_in">str</span>(T / <span class="number">10000</span>))</span><br><span class="line">    <span class="keyword">return</span> T / <span class="number">10000</span></span><br></pre></td></tr></table></figure>

<p>调试与结果展示代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入数据</span></span><br><span class="line">(train_images, train_labels), (test_images, test_labels) = load_data(<span class="string">''</span>)</span><br><span class="line"><span class="comment"># 输出图片</span></span><br><span class="line"><span class="comment"># plt.imshow(train_images[0], cmap='Greys', interpolation='None')</span></span><br><span class="line"><span class="comment"># 初始化输入数据矩阵</span></span><br><span class="line">train_matrix = np.zeros((<span class="number">784</span>,<span class="number">60000</span>))</span><br><span class="line">test_matrix = np.zeros((<span class="number">784</span>,<span class="number">10000</span>))</span><br><span class="line"><span class="comment"># 初始化输出层期望值矩阵</span></span><br><span class="line">train_labels_matrix = np.zeros((<span class="number">10</span>,<span class="number">60000</span>))+<span class="number">0.01</span></span><br><span class="line">test_label_matrix = np.zeros((<span class="number">10</span>,<span class="number">10000</span>))+<span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对60000张图片进行遍历</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">60000</span>):</span><br><span class="line">    <span class="comment"># 测试集的28*28矩阵转化为784的一维数组</span></span><br><span class="line">    img = train_images[i].reshape(train_images.shape[<span class="number">1</span>]*train_images.shape[<span class="number">2</span>])</span><br><span class="line">    <span class="comment"># 进行归一化：除以255，再乘以0.99，最后加上0。01，保证所有的数据都在0.01到1.00之间</span></span><br><span class="line">    train_matrix[:,i] = (img/<span class="number">255.0</span>)*<span class="number">0.99</span>+<span class="number">0.01</span></span><br><span class="line">    <span class="comment"># 建立准确输出结果矩阵，对应的位置标签数值为0.99，其他位置为0.01</span></span><br><span class="line">    <span class="comment"># 第i张图片代表第i列，行数代表正确的标签</span></span><br><span class="line">    train_labels_matrix[train_labels[i],i] = <span class="number">0.99</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 对10000章测试集图片进行处理</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10000</span>):</span><br><span class="line">    <span class="comment"># 训练集的28*28矩阵转化为784的一维数组</span></span><br><span class="line">    test_img = test_images[i].reshape(test_images.shape[<span class="number">1</span>] * test_images.shape[<span class="number">2</span>])</span><br><span class="line">    <span class="comment"># 更新输入到神经网络中的训练集矩阵</span></span><br><span class="line">    test_matrix[:,i] = (test_img/<span class="number">255.0</span>)*<span class="number">0.99</span>+<span class="number">0.01</span></span><br><span class="line">    <span class="comment"># 建立准确输出结果矩阵，对应的位置标签数值为0.99，其他位置为0.01</span></span><br><span class="line">    test_label_matrix[test_labels[i],i] = <span class="number">0.99</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 学习率</span></span><br><span class="line">learn_rate = <span class="number">0.000025</span></span><br><span class="line"><span class="comment"># 迭代次数</span></span><br><span class="line">epochs = <span class="number">100</span></span><br><span class="line"><span class="comment"># 初始化神经网络</span></span><br><span class="line">nn = NeuralNetwork(<span class="number">784</span>,<span class="number">50</span>,<span class="number">10</span>,learn_rate)</span><br><span class="line"><span class="comment"># 准确率数组</span></span><br><span class="line">train_accuracy = []</span><br><span class="line">test_accuracy = []</span><br><span class="line"><span class="comment"># 进行迭代</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    train_accuracy.append( nn.train(train_matrix,train_labels_matrix,<span class="built_in">str</span>(i)) )</span><br><span class="line">    test_accuracy.append( nn.test(test_matrix,test_label_matrix,<span class="built_in">str</span>(i)) )</span><br><span class="line"><span class="comment"># 画图</span></span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">1</span>,epochs+<span class="number">1</span>),train_accuracy,<span class="string">'y'</span>)</span><br><span class="line">plt.plot(<span class="built_in">range</span>(<span class="number">1</span>,epochs+<span class="number">1</span>),test_accuracy,<span class="string">'g'</span>)</span><br><span class="line">plt.legend(labels = (<span class="string">'train accuracy'</span>, <span class="string">'test accuracy'</span>), loc = <span class="string">'lower right'</span>) <span class="comment"># legend placed at lower right</span></span><br><span class="line">plt.title(<span class="string">"learn rate: "</span>+<span class="built_in">str</span>(learn_rate))</span><br><span class="line">plt.xlabel(<span class="string">'iteration'</span>)</span><br><span class="line">plt.ylabel(<span class="string">'accuracy'</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<h1 id="实验结果分析"><a href="#实验结果分析" class="headerlink" title="实验结果分析"></a>实验结果分析</h1><p>当学习率为0.1时，由于学习率过大导致更新的权重过大使得权重数组全为负值，继而在之后的迭代中计算激活能时是一个极大的复数，带入sigmod函数趋近于0，从而导致权值不再更新，正确率维持在0.1更新。</p>
<img src="/2022/01/10/%E5%AE%9E%E9%AA%8C%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%A2%84%E6%B5%8BFashion%E2%80%94MNIST%E6%95%B0%E6%8D%AE%E9%9B%86/image-20211128165926465.png" class="" title="image-20211128165926465">

<img src="/2022/01/10/%E5%AE%9E%E9%AA%8C%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%A2%84%E6%B5%8BFashion%E2%80%94MNIST%E6%95%B0%E6%8D%AE%E9%9B%86/image-20211128165907966.png" class="" title="image-20211128165907966">

<p>解决的方法是<strong>降低学习率</strong>，不让权值更新的过快，将学习率降低为0.000025时，迭代50次，整个模型有很大的优化：</p>
<img src="/2022/01/10/%E5%AE%9E%E9%AA%8C%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%A2%84%E6%B5%8BFashion%E2%80%94MNIST%E6%95%B0%E6%8D%AE%E9%9B%86/image-20211128170150336.png" class="" title="image-20211128170150336">

<p><strong>提高迭代次数</strong>至200次，预测正确率可以达到75%左右：</p>
<img src="/2022/01/10/%E5%AE%9E%E9%AA%8C%EF%BC%9A%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E9%A2%84%E6%B5%8BFashion%E2%80%94MNIST%E6%95%B0%E6%8D%AE%E9%9B%86/200%E6%AC%A1.png" class="" title="200次">

<h1 id="参考："><a href="#参考：" class="headerlink" title="参考："></a>参考：</h1><p>【1】<a class="link" target="_blank" rel="noopener" href="https://blog.csdn.net/qq_45785407/article/details/121539815">神经网络基础与反向传播_Sunburst7的博客-CSDN博客<i class="fas fa-external-link-alt"></i></a></p>
<p>【2】<a class="link" target="_blank" rel="noopener" href="https://blog.csdn.net/supercally/article/details/54312625">识别MNIST数据集之（二）：用Python实现神经网络_superCally的专栏-CSDN博客<i class="fas fa-external-link-alt"></i></a></p>
<p>【3】<a class="link" target="_blank" rel="noopener" href="https://blog.csdn.net/ebzxw/article/details/81591437"> 用python创建的神经网络–mnist手写数字识别率达到98%_学习机器学习-CSDN博客_mnist手写数字识别python<i class="fas fa-external-link-alt"></i></a></p>
<p>【4】<a class="link" target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_46076729/article/details/108936565">利用Python对MNIST手写数据集进行数字识别（初学者入门级）_仲子_real-CSDN博客_mnist手写数字识别python<i class="fas fa-external-link-alt"></i></a></p>

        </div>

        
            <div class="post-copyright-info">
                <div class="article-copyright-info-container">
    <ul>
        <li>Post title：实验：神经网络预测Fashion—MNIST数据集</li>
        <li>Post author：Sunburst7</li>
        <li>Create time：2022-01-10 23:37:51</li>
        <li>
            Post link：https://sunburst7.github.io/2022/01/10/实验：神经网络预测Fashion—MNIST数据集/
        </li>
        <li>
            Copyright Notice：All articles in this blog are licensed under <a class="license" target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh">BY-NC-SA</a> unless stating additionally.
        </li>
    </ul>
</div>

            </div>
        

        
            <ul class="post-tags-box">
                
                    <li class="tag-item">
                        <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">#机器学习</a>&nbsp;
                    </li>
                
                    <li class="tag-item">
                        <a href="/tags/python/">#python</a>&nbsp;
                    </li>
                
            </ul>
        

        
            <div class="article-nav">
                
                    <div class="article-prev">
                        <a class="prev"
                           rel="prev"
                           href="/2022/01/10/%E5%AE%9E%E9%AA%8C%EF%BC%9Abagging%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E9%A2%84%E6%B5%8BTitanic%E6%95%B0%E6%8D%AE%E9%9B%86/"
                        >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                            <span class="title flex-center">
                                <span class="post-nav-title-item">实验：bagging集成学习预测Titanic数据集</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                        </a>
                    </div>
                
                
                    <div class="article-next">
                        <a class="next"
                           rel="next"
                           href="/2022/01/10/%E5%AE%9E%E9%AA%8C%EF%BC%9A%E5%86%B3%E7%AD%96%E6%A0%91%E5%AE%8C%E6%88%90%E9%B8%A2%E5%B0%BE%E8%8A%B1%E5%8D%89%E5%93%81%E7%A7%8D%E9%A2%84%E6%B5%8B/"
                        >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">实验：决策树完成鸢尾花卉品种预测</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                            <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                        </a>
                    </div>
                
            </div>
        

        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            <footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
              <span>2020</span>
              -
            
            2022&nbsp;<i class="fas fa-heart icon-animate"></i>&nbsp;<a href="/">Sunburst7</a>
        </div>
        
            <script async  src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <div class="website-count info-item">
                
                    <span id="busuanzi_container_site_uv">
                        Visitor Count&nbsp;<span id="busuanzi_value_site_uv"></span>&ensp;
                    </span>
                
                
                    <span id="busuanzi_container_site_pv">
                        Totalview&nbsp;<span id="busuanzi_value_site_pv"></span>
                    </span>
                
            </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.4.5</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        
            <li class="tools-item page-aside-toggle">
                <i class="fas fa-outdent"></i>
            </li>
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-expand-width flex-center">
            <i class="fas fa-arrows-alt-h"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    
        <aside class="page-aside">
            <div class="post-toc-wrap">
    <div class="post-toc">
        <ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E6%95%B0%E6%8D%AE"><span class="nav-number">1.</span> <span class="nav-text">实验数据</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E8%A6%81%E6%B1%82"><span class="nav-number">2.</span> <span class="nav-text">实验要求</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E6%80%9D%E8%B7%AF%E4%B8%8E%E4%BB%A3%E7%A0%81"><span class="nav-number">3.</span> <span class="nav-text">实验思路与代码</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%9D%E5%A7%8B%E7%9A%84%E8%AE%BE%E6%83%B3"><span class="nav-number">3.1.</span> <span class="nav-text">初始的设想</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%94%B9%E8%BF%9B%E6%80%9D%E8%B7%AF%EF%BC%9A%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97"><span class="nav-number">3.2.</span> <span class="nav-text">改进思路：矩阵运算</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90"><span class="nav-number">4.</span> <span class="nav-text">实验结果分析</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%82%E8%80%83%EF%BC%9A"><span class="nav-number">5.</span> <span class="nav-text">参考：</span></a></li></ol>
    </div>
</div>
        </aside>
    

    <div class="image-viewer-container">
    <img src="">
</div>


    
        <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
          <span class="search-input-field-pre">
            <i class="fas fa-keyboard"></i>
          </span>
            <div class="search-input-container">
                <input autocomplete="off"
                       autocorrect="off"
                       autocapitalize="off"
                       placeholder="Search..."
                       spellcheck="false"
                       type="search"
                       class="search-input"
                >
            </div>
            <span class="popup-btn-close">
                <i class="fas fa-times"></i>
            </span>
        </div>
        <div id="search-result">
            <div id="no-result">
                <i class="fas fa-spinner fa-pulse fa-5x fa-fw"></i>
            </div>
        </div>
    </div>
</div>

    

</main>



<script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/utils.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/main.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/header-shrink.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/back2top.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/dark-light-toggle.js"></script>


    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/local-search.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/code-copy.js"></script>



    <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/lazyload.js"></script>


<div class="post-scripts">
    
        <script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/left-side-toggle.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/libs/anime.min.js"></script><script src="//cdn.jsdelivr.net/npm/hexo-theme-keep@3.4.5/source/js/toc.js"></script>
    
</div>



</body>
</html>
